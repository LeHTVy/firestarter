# Model Configuration Templates
# 
# This file defines model configuration templates (temperature, top_p, etc.)
# Actual model names are resolved dynamically from Ollama or specified in autogen_config.yaml
#
# Model names can be:
# - Direct Ollama model names (e.g., "mistral:latest", "qwen2-pentest-v2:latest")
# - Aliases that resolve to full names (e.g., "mistral" â†’ "mistral:latest")
# - Environment variable overrides (e.g., RECON_AGENT_MODEL="qwen2-pentest-v2:latest")

# Default model configurations (used as templates)
default_configs:
  # General purpose / task analysis
  task_analysis:
    temperature: 0.85
    top_p: 0.95
    top_k: 50
    num_predict: 2048
    
  # Web search and synthesis
  web_search_synthesis:
    temperature: 0.7
    top_p: 0.9
    top_k: 40
    num_predict: 4096
    
  # Tool calling / function calling
  function_calling:
    temperature: 0.0
    top_p: 0.9
    top_k: 40
    num_predict: 512
    
  # Pentest specialized
  pentest_specialized:
    temperature: 0.3
    top_p: 0.9
    top_k: 40
    num_predict: 2048

# Model aliases (for backward compatibility and convenience)
aliases:
  mistral: "mistral:latest"
  qwen3: "mistral:latest"  # Legacy alias
  deepseek_r1: "deepseek-r1:latest"
  qwen2_pentest: "qwen2-pentest-v2:latest"
  functiongemma: "json_tool_calling"  # Legacy - now uses tool calling registry

# Default model selection
defaults:
  analysis_model: "mistral:latest"  # For task analysis
  synthesis_model: "deepseek-r1:latest"  # For answer synthesis
  tool_calling_model: "json_tool_calling"  # For tool execution
  
# Model availability check
availability:
  check_on_startup: true
  retry_attempts: 3
  retry_delay: 5
